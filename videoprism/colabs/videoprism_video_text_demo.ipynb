{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b7dfe6f88b84f44866191f9bc4b8b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96b6c86682854715b021785a9ad8101e",
              "IPY_MODEL_e966e510367843c39241c49c4df65cce",
              "IPY_MODEL_f008ec88190642b4b1ac901f9e48a230"
            ],
            "layout": "IPY_MODEL_8b9938c1757946d49d953140973c6b10"
          }
        },
        "96b6c86682854715b021785a9ad8101e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52bfb4cb372b401f86587070c6e89352",
            "placeholder": "​",
            "style": "IPY_MODEL_3835d22a60fd4f9aa073eb31b95c609b",
            "value": "flax_lvt_large_f8r288_repeated.npz: 100%"
          }
        },
        "e966e510367843c39241c49c4df65cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4485395ea3945ba8748583ebc8cde58",
            "max": 2319542188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afa06e1580e544569ce0e99c71696a0c",
            "value": 2319542188
          }
        },
        "f008ec88190642b4b1ac901f9e48a230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9056bc13b54b62b163470f21e00c2e",
            "placeholder": "​",
            "style": "IPY_MODEL_02cc14e49a3b41f59e2f299ea7b9070e",
            "value": " 2.32G/2.32G [00:06&lt;00:00, 1.66GB/s]"
          }
        },
        "8b9938c1757946d49d953140973c6b10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52bfb4cb372b401f86587070c6e89352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3835d22a60fd4f9aa073eb31b95c609b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4485395ea3945ba8748583ebc8cde58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afa06e1580e544569ce0e99c71696a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b9056bc13b54b62b163470f21e00c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02cc14e49a3b41f59e2f299ea7b9070e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikeluck/Deep-Flow-Guided-Video-Inpainting/blob/master/videoprism/colabs/videoprism_video_text_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VideoPrism Video-Text Encoder Demo\n",
        "\n",
        "[![Paper](https://img.shields.io/badge/arXiv-2402.13217-red.svg)](https://arxiv.org/abs/2402.13217)\n",
        "[![Blog](https://img.shields.io/badge/Google_Research-Blog-green.svg)](https://research.google/blog/videoprism-a-foundational-visual-encoder-for-video-understanding/)\n",
        "[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n",
        "\n",
        "This notebook provides an example of video and text feature extraction with a pre-trained VideoPrism video-text model for zero-shot video classification/retrieval.\n",
        "\n",
        "Please run this demo on Google Colab with (faster) or without TPU."
      ],
      "metadata": {
        "id": "KPPUiCpSbm53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "k08qFZ9-cn9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prepare environment\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Fetch VideoPrism repository if Python does not know about it and install\n",
        "# dependencies needed for this notebook.\n",
        "if not os.path.exists(\"videoprism_repo\"):\n",
        "  !git clone --quiet --branch=main --depth=1 \\\n",
        "     https://github.com/google-deepmind/videoprism.git videoprism_repo\n",
        "  os.chdir('./videoprism_repo')\n",
        "  !pip install .\n",
        "  os.chdir('..')\n",
        "\n",
        "# Append VideoPrism code to Python import path.\n",
        "if \"videoprism_repo\" not in sys.path:\n",
        "  sys.path.append(\"videoprism_repo\")\n",
        "\n",
        "# Install missing dependencies.\n",
        "!pip install mediapy\n",
        "\n",
        "import jax\n",
        "from jax.extend import backend\n",
        "import tensorflow as tf\n",
        "\n",
        "# Do not let TF use the GPU or TPUs.\n",
        "tf.config.set_visible_devices([], \"GPU\")\n",
        "tf.config.set_visible_devices([], \"TPU\")\n",
        "\n",
        "print(f\"JAX version:  {jax.__version__}\")\n",
        "print(f\"JAX platform: {backend.get_backend().platform}\")\n",
        "print(f\"JAX devices:  {jax.device_count()}\")"
      ],
      "metadata": {
        "id": "1dfyX8EyVsvL",
        "outputId": "7d457e19-692e-49f1-aa61-4d75e458bc4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapy in /usr/local/lib/python3.11/dist-packages (1.2.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from mediapy) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapy) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapy) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mediapy) (11.3.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (5.2.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (2.9.0.post0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->mediapy) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->mediapy) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapy) (1.17.0)\n",
            "JAX version:  0.5.2\n",
            "JAX platform: tpu\n",
            "JAX devices:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zByA1K0IVKAI"
      },
      "outputs": [],
      "source": [
        "# @title Load dependencies and define utilities\n",
        "\n",
        "import mediapy\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def read_and_preprocess_video(\n",
        "    filename: str, target_num_frames: int, target_frame_size: tuple[int, int]\n",
        "):\n",
        "  \"\"\"Reads and preprocesses a video.\"\"\"\n",
        "\n",
        "  frames = mediapy.read_video(filename)\n",
        "\n",
        "  # Sample to target number of frames.\n",
        "  frame_indices = np.linspace(\n",
        "      0, len(frames), num=target_num_frames, endpoint=False, dtype=np.int32\n",
        "  )\n",
        "  frames = np.array([frames[i] for i in frame_indices])\n",
        "\n",
        "  # Resize to target size.\n",
        "  original_height, original_width = frames.shape[-3:-1]\n",
        "  target_height, target_width = target_frame_size\n",
        "  assert (\n",
        "      original_height * target_width == original_width * target_height\n",
        "  ), 'Currently does not support aspect ratio mismatch.'\n",
        "  frames = mediapy.resize_video(frames, shape=target_frame_size)\n",
        "\n",
        "  # Normalize pixel values to [0.0, 1.0].\n",
        "  frames = mediapy.to_float01(frames)\n",
        "\n",
        "  return frames\n",
        "\n",
        "\n",
        "def compute_similarity_matrix(\n",
        "    video_embeddings,\n",
        "    text_embeddings,\n",
        "    temperature: float,\n",
        "    apply_softmax: str | None = None,\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Computes cosine similarity matrix.\"\"\"\n",
        "  assert apply_softmax in [None, 'over_texts', 'over_videos']\n",
        "  emb_dim = video_embeddings[0].shape[-1]\n",
        "  assert emb_dim == text_embeddings[0].shape[-1]\n",
        "\n",
        "  video_embeddings = np.array(video_embeddings).reshape(-1, emb_dim)\n",
        "  text_embeddings = np.array(text_embeddings).reshape(-1, emb_dim)\n",
        "  similarity_matrix = np.dot(video_embeddings, text_embeddings.T)\n",
        "\n",
        "  if temperature is not None:\n",
        "    similarity_matrix /= temperature\n",
        "\n",
        "  if apply_softmax == 'over_videos':\n",
        "    similarity_matrix = np.exp(similarity_matrix)\n",
        "    similarity_matrix = similarity_matrix / np.sum(\n",
        "        similarity_matrix, axis=0, keepdims=True\n",
        "    )\n",
        "  elif apply_softmax == 'over_texts':\n",
        "    similarity_matrix = np.exp(similarity_matrix)\n",
        "    similarity_matrix = similarity_matrix / np.sum(\n",
        "        similarity_matrix, axis=1, keepdims=True\n",
        "    )\n",
        "\n",
        "  return similarity_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load model\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from videoprism import models as vp\n",
        "\n",
        "# MODEL_NAME = 'videoprism_lvt_public_v1_base'  # @param ['videoprism_lvt_public_v1_base', 'videoprism_lvt_public_v1_large'] {allow-input: false}\n",
        "MODEL_NAME = 'videoprism_lvt_public_v1_large'\n",
        "NUM_FRAMES = 16\n",
        "FRAME_SIZE = 288\n",
        "\n",
        "flax_model = vp.get_model(MODEL_NAME)\n",
        "loaded_state = vp.load_pretrained_weights(MODEL_NAME)\n",
        "text_tokenizer = vp.load_text_tokenizer('c4_en')\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def forward_fn(inputs, text_token_ids, text_paddings, train=False):\n",
        "  return flax_model.apply(\n",
        "      loaded_state,\n",
        "      inputs,\n",
        "      text_token_ids,\n",
        "      text_paddings,\n",
        "      train=train,\n",
        "  )"
      ],
      "metadata": {
        "id": "WnYuzSgrXCL1",
        "outputId": "ccdb090a-4c44-4927-f4b3-9ca86ed65973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "4b7dfe6f88b84f44866191f9bc4b8b10",
            "96b6c86682854715b021785a9ad8101e",
            "e966e510367843c39241c49c4df65cce",
            "f008ec88190642b4b1ac901f9e48a230",
            "8b9938c1757946d49d953140973c6b10",
            "52bfb4cb372b401f86587070c6e89352",
            "3835d22a60fd4f9aa073eb31b95c609b",
            "d4485395ea3945ba8748583ebc8cde58",
            "afa06e1580e544569ce0e99c71696a0c",
            "1b9056bc13b54b62b163470f21e00c2e",
            "02cc14e49a3b41f59e2f299ea7b9070e"
          ]
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "flax_lvt_large_f8r288_repeated.npz:   0%|          | 0.00/2.32G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b7dfe6f88b84f44866191f9bc4b8b10"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Zero-shot Video Classification/Retrieval\n",
        "\n",
        "In this example, we extract the embedding of an input video, and the embeddings of five senetence. We measure the cosine similarites between the videos and sentences."
      ],
      "metadata": {
        "id": "AliScLC0jo1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Specify input video\n",
        "VIDEO_FILE_PATH = 'videoprism_repo/videoprism/assets/water_bottle_drumming.mp4'  # @param {type: \"string\"}\n",
        "\n",
        "frames = read_and_preprocess_video(\n",
        "    VIDEO_FILE_PATH,\n",
        "    target_num_frames=NUM_FRAMES,\n",
        "    target_frame_size=[FRAME_SIZE, FRAME_SIZE],\n",
        ")\n",
        "frames = jnp.asarray(frames[None, ...])  # Add batch dimension."
      ],
      "metadata": {
        "id": "sESN_CjfEiQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Specify input text queries\n",
        "TEXT_QUERY_CSV = 'playing drums,sitting,playing flute,playing at playground,concert'  # @param {type: \"string\"}\n",
        "PROMPT_TEMPLATE = 'a video of {}.'\n",
        "\n",
        "text_queries = TEXT_QUERY_CSV.split(',')\n",
        "text_queries = [PROMPT_TEMPLATE.format(t) for t in text_queries]\n",
        "text_ids, text_paddings = vp.tokenize_texts(text_tokenizer, text_queries)\n",
        "\n",
        "print('Input text queries:')\n",
        "for i, text in enumerate(text_queries):\n",
        "  print(f'({i + 1}) {text}')"
      ],
      "metadata": {
        "id": "kLzkhP8CYUYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Compute video-to-text retrieval results\n",
        "video_embeddings, text_embeddings, _ = forward_fn(\n",
        "    frames, text_ids, text_paddings)\n",
        "\n",
        "TEMPERATURE = 0.01  # @param {type: \"number\"}\n",
        "similarity_matrix = compute_similarity_matrix(\n",
        "    video_embeddings,\n",
        "    text_embeddings,\n",
        "    temperature=TEMPERATURE,\n",
        "    apply_softmax='over_texts',\n",
        ")"
      ],
      "metadata": {
        "id": "bfwT93Yz5oi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v2t_similarity_vector = similarity_matrix[0]\n",
        "top_indices = np.argsort(v2t_similarity_vector)[::-1]\n",
        "\n",
        "print(f'Query video: {os.path.basename(VIDEO_FILE_PATH)}')\n",
        "mediapy.show_video(frames[0], fps=6.0)\n",
        "\n",
        "for k, j in enumerate(top_indices):\n",
        "  print(\n",
        "      'Top-%d retrieved text: %s [Similarity = %0.4f]'\n",
        "      % (k + 1, text_queries[j], v2t_similarity_vector[j])\n",
        "  )\n",
        "print(f'\\nThis is {text_queries[top_indices[0]]}')"
      ],
      "metadata": {
        "id": "lZ8woxde6t_S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}